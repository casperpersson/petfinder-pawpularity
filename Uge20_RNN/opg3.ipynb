{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfebcbf",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3824d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b0b3f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e8179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: torch.Size([20]) \n",
      "\n",
      " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "        15., 16., 17., 18., 19., 20.])\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 1\n",
    "SEQ_LENGTH = 5\n",
    "HIDDEN_SIZE = 2\n",
    "NUM_LAYERS = 1\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 20000\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "data = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
    "print(\"Data:\", data.shape, \"\\n\\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "96e69a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([15, 5, 1]) \n",
      "\n",
      " tensor([[[ 1.],\n",
      "         [ 2.],\n",
      "         [ 3.],\n",
      "         [ 4.],\n",
      "         [ 5.]],\n",
      "\n",
      "        [[ 2.],\n",
      "         [ 3.],\n",
      "         [ 4.],\n",
      "         [ 5.],\n",
      "         [ 6.]],\n",
      "\n",
      "        [[ 3.],\n",
      "         [ 4.],\n",
      "         [ 5.],\n",
      "         [ 6.],\n",
      "         [ 7.]],\n",
      "\n",
      "        [[ 4.],\n",
      "         [ 5.],\n",
      "         [ 6.],\n",
      "         [ 7.],\n",
      "         [ 8.]],\n",
      "\n",
      "        [[ 5.],\n",
      "         [ 6.],\n",
      "         [ 7.],\n",
      "         [ 8.],\n",
      "         [ 9.]],\n",
      "\n",
      "        [[ 6.],\n",
      "         [ 7.],\n",
      "         [ 8.],\n",
      "         [ 9.],\n",
      "         [10.]],\n",
      "\n",
      "        [[ 7.],\n",
      "         [ 8.],\n",
      "         [ 9.],\n",
      "         [10.],\n",
      "         [11.]],\n",
      "\n",
      "        [[ 8.],\n",
      "         [ 9.],\n",
      "         [10.],\n",
      "         [11.],\n",
      "         [12.]],\n",
      "\n",
      "        [[ 9.],\n",
      "         [10.],\n",
      "         [11.],\n",
      "         [12.],\n",
      "         [13.]],\n",
      "\n",
      "        [[10.],\n",
      "         [11.],\n",
      "         [12.],\n",
      "         [13.],\n",
      "         [14.]],\n",
      "\n",
      "        [[11.],\n",
      "         [12.],\n",
      "         [13.],\n",
      "         [14.],\n",
      "         [15.]],\n",
      "\n",
      "        [[12.],\n",
      "         [13.],\n",
      "         [14.],\n",
      "         [15.],\n",
      "         [16.]],\n",
      "\n",
      "        [[13.],\n",
      "         [14.],\n",
      "         [15.],\n",
      "         [16.],\n",
      "         [17.]],\n",
      "\n",
      "        [[14.],\n",
      "         [15.],\n",
      "         [16.],\n",
      "         [17.],\n",
      "         [18.]],\n",
      "\n",
      "        [[15.],\n",
      "         [16.],\n",
      "         [17.],\n",
      "         [18.],\n",
      "         [19.]]])\n",
      "y: torch.Size([15, 1]) \n",
      "\n",
      " tensor([[ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.],\n",
      "        [11.],\n",
      "        [12.],\n",
      "        [13.],\n",
      "        [14.],\n",
      "        [15.],\n",
      "        [16.],\n",
      "        [17.],\n",
      "        [18.],\n",
      "        [19.],\n",
      "        [20.]])\n"
     ]
    }
   ],
   "source": [
    "# Chunck the data into 15 chuncks of length 5\n",
    "chunks = []\n",
    "targets = []\n",
    "for i in range(len(data)-SEQ_LENGTH):\n",
    "    chunks.append(data[i:(i+SEQ_LENGTH)])\n",
    "    targets.append(data[i+SEQ_LENGTH])\n",
    "\n",
    "\n",
    "\n",
    "X = torch.stack(chunks).unsqueeze(-1)\n",
    "Y = torch.stack(targets).unsqueeze(-1)\n",
    "print(\"X:\", X.shape, \"\\n\\n\", X)\n",
    "print(\"y:\", Y.shape, \"\\n\\n\", Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f1010",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4bc93ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers =\n",
    "1, batch_first=True)\n",
    "\n",
    "inputs = data.view(BATCH_SIZE, SEQ_LENGTH, INPUT_SIZE)\n",
    "out, h_n = rnn(inputs)\n",
    "\n",
    "fc = nn.Linear(HIDDEN_SIZE, 1)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(rnn.parameters()) + list(fc.parameters()), lr=LEARNING_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de97572",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d6d3659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Loss: 192.3123\n",
      "Epoch 40/1000, Loss: 175.9007\n",
      "Epoch 60/1000, Loss: 146.4844\n",
      "Epoch 80/1000, Loss: 129.6814\n",
      "Epoch 100/1000, Loss: 115.7928\n",
      "Epoch 120/1000, Loss: 103.8293\n",
      "Epoch 140/1000, Loss: 93.3349\n",
      "Epoch 160/1000, Loss: 84.0482\n",
      "Epoch 180/1000, Loss: 75.7985\n",
      "Epoch 200/1000, Loss: 68.4616\n",
      "Epoch 220/1000, Loss: 61.9394\n",
      "Epoch 240/1000, Loss: 56.1497\n",
      "Epoch 260/1000, Loss: 51.0215\n",
      "Epoch 280/1000, Loss: 46.4911\n",
      "Epoch 300/1000, Loss: 42.5007\n",
      "Epoch 320/1000, Loss: 38.9971\n",
      "Epoch 340/1000, Loss: 35.9308\n",
      "Epoch 360/1000, Loss: 33.2542\n",
      "Epoch 380/1000, Loss: 30.7835\n",
      "Epoch 400/1000, Loss: 27.3650\n",
      "Epoch 420/1000, Loss: 24.8820\n",
      "Epoch 440/1000, Loss: 22.6994\n",
      "Epoch 460/1000, Loss: 20.7293\n",
      "Epoch 480/1000, Loss: 18.9481\n",
      "Epoch 500/1000, Loss: 17.3356\n",
      "Epoch 520/1000, Loss: 15.8747\n",
      "Epoch 540/1000, Loss: 14.5501\n",
      "Epoch 560/1000, Loss: 13.3478\n",
      "Epoch 580/1000, Loss: 12.2554\n",
      "Epoch 600/1000, Loss: 11.2615\n",
      "Epoch 620/1000, Loss: 10.3547\n",
      "Epoch 640/1000, Loss: 9.5272\n",
      "Epoch 660/1000, Loss: 8.7726\n",
      "Epoch 680/1000, Loss: 8.0835\n",
      "Epoch 700/1000, Loss: 7.4542\n",
      "Epoch 720/1000, Loss: 6.8790\n",
      "Epoch 740/1000, Loss: 6.3529\n",
      "Epoch 760/1000, Loss: 5.8714\n",
      "Epoch 780/1000, Loss: 5.4302\n",
      "Epoch 800/1000, Loss: 5.0257\n",
      "Epoch 820/1000, Loss: 4.6547\n",
      "Epoch 840/1000, Loss: 4.3140\n",
      "Epoch 860/1000, Loss: 4.0011\n",
      "Epoch 880/1000, Loss: 3.7134\n",
      "Epoch 900/1000, Loss: 3.4487\n",
      "Epoch 920/1000, Loss: 3.2050\n",
      "Epoch 940/1000, Loss: 2.9805\n",
      "Epoch 960/1000, Loss: 2.7736\n",
      "Epoch 980/1000, Loss: 2.5827\n",
      "Epoch 1000/1000, Loss: 2.4064\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Forward pass\n",
    "    out, _ = rnn(X)                # out: (batch, seq_len, hidden)\n",
    "    last_hidden = out[:, -1, :]    # use the last time step\n",
    "    prediction = fc(last_hidden)   # map to output\n",
    " \n",
    "    # Compute loss\n",
    "    loss = criterion(prediction, Y)\n",
    " \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5414e",
   "metadata": {},
   "source": [
    "# Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b92e2c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction for [16, 17, 18, 19, 20] → 15.74\n"
     ]
    }
   ],
   "source": [
    "#  Test prediction\n",
    "test_seq = torch.tensor([16.0, 17.0, 18.0, 19.0, 20.0]).view(1, SEQ_LENGTH, 1)\n",
    "out, _ = rnn(test_seq)\n",
    "predicted = fc(out[:, -1, :])\n",
    "print(f\"\\nPrediction for [16, 17, 18, 19, 20] → {predicted.item():.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
